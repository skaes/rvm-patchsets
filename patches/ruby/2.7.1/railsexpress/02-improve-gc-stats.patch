improve gc stats

From: Stefan Kaes <skaes@railsexpress.de>


---
 gc.c                  |  176 ++++++++++++++++++++++++++++++++++++++++++++++++-
 gc.rb                 |   86 ++++++++++++++++++++++++
 include/ruby/intern.h |    8 ++
 3 files changed, 266 insertions(+), 4 deletions(-)

diff --git a/gc.c b/gc.c
index 0c007dffe6..e034a3cb67 100644
--- a/gc.c
+++ b/gc.c
@@ -698,6 +698,8 @@ typedef struct rb_objspace {
 #if GC_ENABLE_INCREMENTAL_MARK
 	unsigned int during_incremental_marking : 1;
 #endif
+        int collect_gc_stats;
+        int verbose_gc_stats;
     } flags;
 
     rb_event_flag_t hook_events;
@@ -772,14 +774,21 @@ typedef struct rb_objspace {
 
 	/* temporary profiling space */
 	double gc_sweep_start_time;
+        double gc_mark_start_time;
+
 	size_t total_allocated_objects_at_gc_start;
 	size_t heap_used_at_gc_start;
 
 	/* basic statistics */
 	size_t count;
+        double time;
 	size_t total_freed_objects;
 	size_t total_allocated_pages;
 	size_t total_freed_pages;
+        size_t total_mallocs;
+        size_t total_malloced_bytes;
+        size_t live_after_last_sweep;
+
     } profile;
     struct gc_list *global_list;
 
@@ -920,6 +929,7 @@ VALUE *ruby_initial_gc_stress_ptr = &ruby_initial_gc_stress;
 #define heap_tomb               (&objspace->tomb_heap)
 #define dont_gc 		objspace->flags.dont_gc
 #define during_gc		objspace->flags.during_gc
+#define collect_gc_stats        objspace->flags.collect_gc_stats
 #define finalizing		objspace->atomic_flags.finalizing
 #define finalizer_table 	objspace->finalizer_table
 #define global_list		objspace->global_list
@@ -6894,6 +6904,107 @@ rb_gc_writebarrier_remember(VALUE obj)
 
 static st_table *rgengc_unprotect_logging_table;
 
+VALUE
+rb_gc_enable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 1;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_enable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_enable_stats();
+}
+
+VALUE
+rb_gc_disable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 0;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_disable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_disable_stats();
+}
+
+
+VALUE
+rb_gc_stats_enabled()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return collect_gc_stats ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_stats_enabled(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_stats_enabled();
+}
+
+double rb_gc_total_time()
+{
+    return rb_objspace.profile.time;
+}
+
+static VALUE
+gc_time(rb_execution_context_t *ec, VALUE _)
+{
+    return DBL2NUM(1000000*rb_objspace.profile.time);
+}
+
+VALUE
+rb_gc_heap_slots()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(heap_allocated_pages * HEAP_PAGE_OBJ_LIMIT);
+}
+
+static
+VALUE gc_heap_slots(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots();
+}
+
+VALUE
+rb_gc_heap_slots_live_after_last_gc()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(objspace->profile.live_after_last_sweep);
+}
+
+static
+VALUE gc_heap_slots_live_after_last_gc(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots_live_after_last_gc();
+}
+
+size_t rb_gc_total_mallocs() {
+    return rb_objspace.profile.total_mallocs;
+}
+
+static VALUE
+gc_total_mallocs(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_mallocs);
+}
+
+size_t rb_gc_total_malloced_bytes(void) {
+    return rb_objspace.profile.total_malloced_bytes;
+}
+
+static VALUE
+gc_total_malloced_bytes(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_malloced_bytes);
+}
+
 static int
 rgengc_unprotect_logging_exit_func_i(st_data_t key, st_data_t val, st_data_t arg)
 {
@@ -9720,6 +9831,10 @@ objspace_malloc_increase(rb_objspace_t *objspace, void *mem, size_t new_size, si
 {
     if (new_size > old_size) {
 	ATOMIC_SIZE_ADD(malloc_increase, new_size - old_size);
+        if (collect_gc_stats) {
+            ATOMIC_SIZE_ADD(objspace->profile.total_mallocs, 1);
+            ATOMIC_SIZE_ADD(objspace->profile.total_malloced_bytes, new_size - old_size);
+        }
 #if RGENGC_ESTIMATE_OLDMALLOC
 	ATOMIC_SIZE_ADD(objspace->rgengc.oldmalloc_increase, new_size - old_size);
 #endif
@@ -10299,6 +10414,12 @@ gc_malloc_allocated_size(VALUE self)
     return UINT2NUM(rb_objspace.malloc_params.allocated_size);
 }
 
+size_t
+rb_gc_malloc_allocated_size(void)
+{
+    return rb_objspace.malloc_params.allocated_size;
+}
+
 /*
  *  call-seq:
  *     GC.malloc_allocations -> Integer
@@ -10313,6 +10434,12 @@ gc_malloc_allocations(VALUE self)
 {
     return UINT2NUM(rb_objspace.malloc_params.allocations);
 }
+
+size_t
+rb_gc_malloc_allocations(void)
+{
+    return rb_objspace.malloc_params.allocations;
+}
 #endif
 
 void
@@ -10895,6 +11022,14 @@ gc_prof_mark_timer_start(rb_objspace_t *objspace)
 #if GC_PROFILE_MORE_DETAIL
     if (gc_prof_enabled(objspace)) {
 	gc_prof_record(objspace)->gc_mark_time = getrusage_time();
+    } else {
+        if (collect_gc_stats) {
+          objspace->profile.gc_mark_start_time = getrusage_time();
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.gc_mark_start_time = getrusage_time();
     }
 #endif
 }
@@ -10907,6 +11042,17 @@ gc_prof_mark_timer_stop(rb_objspace_t *objspace)
     if (gc_prof_enabled(objspace)) {
         gc_profile_record *record = gc_prof_record(objspace);
 	record->gc_mark_time = elapsed_time_from(record->gc_mark_time);
+        if (collect_gc_stats) {
+            objspace->profile.time += record->gc_mark_time;
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
     }
 #endif
 }
@@ -10918,9 +11064,13 @@ gc_prof_sweep_timer_start(rb_objspace_t *objspace)
     if (gc_prof_enabled(objspace)) {
 	gc_profile_record *record = gc_prof_record(objspace);
 
-	if (record->gc_time > 0 || GC_PROFILE_MORE_DETAIL) {
+	if (record->gc_time > 0 || GC_PROFILE_MORE_DETAIL || collect_gc_stats) {
 	    objspace->profile.gc_sweep_start_time = getrusage_time();
-	}
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.gc_sweep_start_time = getrusage_time();
+        }
     }
 }
 
@@ -10937,16 +11087,30 @@ gc_prof_sweep_timer_stop(rb_objspace_t *objspace)
 	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
 	    /* need to accumulate GC time for lazy sweep after gc() */
 	    record->gc_time += sweep_time;
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
 	}
 	else if (GC_PROFILE_MORE_DETAIL) {
 	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
-	}
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
+	} else {
+            if (collect_gc_stats) {
+                objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+            }
+        }
 
 #if GC_PROFILE_MORE_DETAIL
 	record->gc_sweep_time += sweep_time;
 	if (heap_pages_deferred_final) record->flags |= GPR_FLAG_HAVE_FINALIZE;
 #endif
 	if (heap_pages_deferred_final) objspace->profile.latest_gc_info |= GPR_FLAG_HAVE_FINALIZE;
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+        }
     }
 }
 
@@ -10965,9 +11129,13 @@ gc_prof_set_malloc_info(rb_objspace_t *objspace)
 static inline void
 gc_prof_set_heap_info(rb_objspace_t *objspace)
 {
+    if (objspace->profile.total_allocated_objects_at_gc_start > objspace->profile.total_freed_objects)
+        objspace->profile.live_after_last_sweep =
+            objspace->profile.total_allocated_objects_at_gc_start - objspace->profile.total_freed_objects;
+
     if (gc_prof_enabled(objspace)) {
 	gc_profile_record *record = gc_prof_record(objspace);
-	size_t live = objspace->profile.total_allocated_objects_at_gc_start - objspace->profile.total_freed_objects;
+        size_t live = objspace->profile.live_after_last_sweep;
 	size_t total = objspace->profile.heap_used_at_gc_start * HEAP_PAGE_OBJ_LIMIT;
 
 #if GC_PROFILE_MORE_DETAIL
diff --git a/gc.rb b/gc.rb
index fcfa48fbe1..d4f6482131 100644
--- a/gc.rb
+++ b/gc.rb
@@ -158,6 +158,92 @@ def self.latest_gc_info hash_or_key = nil
   def self.compact
     __builtin_rb_gc_compact
   end
+
+  # call-seq:
+  #    GC.enable_stats	  => true or false
+  #
+  # Enables garbage collection statistics, returning <code>true</code> if garbage
+  # collection statistics was already enabled.
+  #
+  #    GC.enable_stats	 #=> false or true
+  #    GC.enable_stats	 #=> true
+  def self.enable_stats
+    __builtin_gc_enable_stats
+  end
+
+  #   call-seq:
+  #    GC.disable_stats	   => true or false
+  #
+  # Disables garbage collection statistics, returning <code>true</code> if garbage
+  # collection statistics was already disabled.
+  #
+  #    GC.disable_stats	  #=> false or true
+  #    GC.disable_stats	  #=> true
+  def self.disable_stats
+    __builtin_gc_disable_stats
+  end
+
+  # call-seq:
+  #    GC.stats_enabled?    => true or false
+  #
+  # Check whether GC stats have been enabled.
+  #
+  #    GC.stats_enabled?   #=> false or true
+  def self.stats_enabled?
+    __builtin_gc_stats_enabled
+  end
+
+  #   call-seq:
+  #    GC.time	  => Integer
+  #
+  # Returns the time spent during garbage collection while GC statistics collection
+  # was enabled (in micro seconds).
+  #
+  #    GC.time	  #=> 20000
+  def self.time
+    __builtin_gc_time
+  end
+
+  #  call-seq:
+  #	GC.heap_slots	=> Integer
+  #
+  #  Returns the number of heap slots available for object allocations.
+  #
+  #	GC.heap_slots	#=> 10000
+  def self.heap_slots
+    __builtin_gc_heap_slots
+  end
+
+  # call-seq:
+  #    GC.heap_slots_live_after_last_gc	   => Integer
+  #
+  # Returns the number of heap slots which were live after the last garbage collection.
+  #
+  #    GC.heap_slots_live_after_last_gc	   #=> 231223
+  def self.heap_slots_live_after_last_gc
+    __builtin_gc_heap_slots_live_after_last_gc
+  end
+
+  #   call-seq:
+  #	 GC.total_mallocs	   => Integer
+  #
+  #   Returns the number malloc calls. Might wrap around.
+  #
+  #	 GC.total_mallocs	   #=> 324234323246
+  def self.total_mallocs
+    __builtin_gc_total_mallocs
+  end
+
+  #   call-seq:
+  #	 GC.total_malloced_bytes	   => Integer
+  #
+  #   Returns the number of bytes allocated. Might wrap around.
+  #
+  #	 GC.total_malloced_bytes	   #=> 354656256432446
+  def self.total_malloced_bytes
+    __builtin_gc_total_malloced_bytes
+  end
+
 end
 
 module ObjectSpace
diff --git a/include/ruby/intern.h b/include/ruby/intern.h
index 2f60fb569e..3e3ed90927 100644
--- a/include/ruby/intern.h
+++ b/include/ruby/intern.h
@@ -544,6 +544,9 @@ void rb_gc(void);
 void rb_gc_copy_finalizer(VALUE,VALUE);
 VALUE rb_gc_enable(void);
 VALUE rb_gc_disable(void);
+VALUE rb_gc_enable_stats(void);
+VALUE rb_gc_disable_stats(void);
+VALUE rb_gc_stats_enabled(void);
 VALUE rb_gc_start(void);
 VALUE rb_define_finalizer(VALUE, VALUE);
 VALUE rb_undefine_finalizer(VALUE);
@@ -551,6 +554,11 @@ size_t rb_gc_count(void);
 size_t rb_gc_stat(VALUE);
 VALUE rb_gc_latest_gc_info(VALUE);
 void rb_gc_adjust_memory_usage(ssize_t);
+double rb_gc_total_time(void);
+VALUE rb_gc_heap_slots(void);
+VALUE rb_gc_heap_slots_live_after_last_gc(void);
+size_t rb_gc_total_mallocs(void);
+size_t rb_gc_total_malloced_bytes(void);
 /* hash.c */
 void rb_st_foreach_safe(struct st_table *, int (*)(st_data_t, st_data_t, st_data_t), st_data_t);
 #define st_foreach_safe rb_st_foreach_safe
